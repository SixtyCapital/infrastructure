apiVersion: v1
kind: Service
metadata:
  name: airflow-web
  labels:
    app: airflow-web
    tier: web
    stack: airflow
spec:
  type: NodePort
  selector:
    app: airflow-web
  ports:
    - protocol: TCP
      port: 8080
      nodePort: 32080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: airflow-web
    tier: web
    stack: airflow
  name: airflow-web
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow-web
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: airflow-web
        tier: web
        stack: airflow
    spec:
      containers:
      - name: airflow
        image: gcr.io/sixty-secure/conductor:master
        command:
        - airflow
        args:
        - webserver
        envFrom:
        - configMapRef:
            name: airflow-env
        imagePullPolicy: Always
        ports:
        - containerPort: 8080
          protocol: TCP
        resources:
          limits:
            memory: 2Gi
          requests:
            memory: 1Gi
            cpu: 1000m
      - image: gcr.io/cloudsql-docker/gce-proxy:1.14
        name: cloudsql-proxy
        command: ["/cloud_sql_proxy"]
        args: ["-instances=$(DB_CONNECTION_NAME)=tcp:5432"]
        envFrom:
        - configMapRef:
            name: airflow-env
      restartPolicy: Always
      nodeSelector:
        cloud.google.com/gke-nodepool: large-preemptible
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: airflow-scheduler
    tier: scheduler
    stack: airflow
  name: airflow-scheduler
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow-scheduler
  strategy:
    type: Recreate
    rollingUpdate: null
  template:
    metadata:
      labels:
        app: airflow-scheduler
        tier: scheduler
        stack: airflow
    spec:
      containers:
      - name: airflow
        image: gcr.io/sixty-secure/conductor:master
        command:
        - bash
        args:
        # need to run initdb at start of airflow
        - '-c "$(AIRFLOW_HOME)/airflow-init.sh && airflow scheduler"'
        envFrom:
        - configMapRef:
            name: airflow-env
        imagePullPolicy: Always
        resources:
          limits:
            memory: 2Gi
          requests:
            memory: 500Mi
            cpu: 3000m
      - image: gcr.io/cloudsql-docker/gce-proxy:1.14
        name: cloudsql-proxy
        command: ["/cloud_sql_proxy"]
        args: ["-instances=$(DB_CONNECTION_NAME)=tcp:5432"]
        envFrom:
        - configMapRef:
            name: airflow-env
      restartPolicy: Always
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: airflow-worker
    tier: worker
    stack: airflow
  name: airflow-worker
spec:
  replicas: 32
  selector:
    matchLabels:
      app: airflow-worker
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: airflow-worker
        tier: worker
        stack: airflow
    spec:
      containers:
      - name: airflow
        image: gcr.io/sixty-secure/conductor:master
        command:
        - airflow
        args:
        - worker
        envFrom:
        - configMapRef:
            name: airflow-env
        imagePullPolicy: Always
        ports:
        - containerPort: 8793
          protocol: TCP
        resources:
          limits:
            memory: 12Gi
            cpu: 1000m
          requests:
            memory: 1Gi
            cpu: 300m
      - image: gcr.io/cloudsql-docker/gce-proxy:1.14
        name: cloudsql-proxy
        command: ["/cloud_sql_proxy"]
        args: ["-instances=$(DB_CONNECTION_NAME)=tcp:5432"]
        envFrom:
        - configMapRef:
            name: airflow-env
      restartPolicy: Always
      nodeSelector:
        cloud.google.com/gke-nodepool: large-preemptible
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: celery-redis
  labels:
    app: celery-redis
    role: master
    tier: backend
    db: redis
spec:
  selector:
    matchLabels:
      app: celery-redis
  replicas: 1
  template:
    metadata:
      labels:
        app: celery-redis
        role: master
        tier: backend
        db: redis
    spec:
      containers:
      - name: celery-redis
        image: launcher.gcr.io/google/redis4
        args: [
          "--maxmemory", "300Mi",
          "--maxmemory-policy", "allkeys-lru",
          "--timeout", "10800",  # 3 hours
          "--tcp-backlog", "10000"
          ]
        ports:
        - containerPort: 6379
        resources:
          requests:
            memory: 300Mi
      volumes:
      - name: celery-redis-data
        persistentVolumeClaim:
          claimName: celery-redis-data
      nodeSelector:
        cloud.google.com/gke-nodepool: small
---
# Request a persistent volume from the cluster using a Persistent Volume Claim.
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: celery-redis-data
  annotations:
    volume.alpha.kubernetes.io/storage-class: default
spec:
  accessModes: [ReadWriteOnce]
  resources:
    requests:
      storage: 10Gi
---
apiVersion: v1
kind: Service
metadata:
  name: celery-redis
  labels:
    app: celery-redis
    role: master
    tier: backend
    db: redis
spec:
  ports:
    # the port that this service should serve on
  - port: 6379
    targetPort: 6379
  selector:
    app: celery-redis
    role: master
    tier: backend