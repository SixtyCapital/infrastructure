apiVersion: v1
kind: Service
metadata:
  name: airflow-web
  labels:
    app: airflow-web
    tier: web
    stack: airflow
spec:
  type: NodePort
  selector:
    app: airflow-web
  ports:
    - name: airflow-web
      protocol: TCP
      port: 8080
      targetPort: airflow-web
      nodePort: 32080
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  labels:
    app: airflow-web
    tier: web
    stack: airflow
  name: airflow-web
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow-web
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
    type: RollingUpdate
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: airflow-web
        tier: web
        stack: airflow
    spec:
      containers:
      - name: airflow-web
        image: gcr.io/sixty-secure/conductor:commodity-in-conductor
        command:
        - /usr/local/bin/airflow-entry.sh
        - webserver
        envFrom:
        - configMapRef:
            name: airflow-env
        imagePullPolicy: Always
        ports:
        - containerPort: 8080
          protocol: TCP
        resources:
          limits:
            memory: 1Gi
          requests:
            memory: 1Gi
      - image: gcr.io/cloudsql-docker/gce-proxy:1.11
        name: cloudsql-proxy
        command: ["/cloud_sql_proxy"]
        args: ["-instances=$(DB_CONNECTION_NAME)=tcp:5432"]
        envFrom:
        - configMapRef:
            name: airflow-env
      restartPolicy: Always
      nodeSelector:
        cloud.google.com/gke-nodepool: small
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  labels:
    app: airflow-scheduler
    tier: scheduler
    stack: airflow
  name: airflow-scheduler
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow-scheduler
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
    type: RollingUpdate
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: airflow-scheduler
        tier: scheduler
        stack: airflow
    spec:
      containers:
      - name: airflow-scheduler
        image: gcr.io/sixty-secure/conductor:commodity-in-conductor
        command:
        - /usr/local/bin/airflow-entry.sh
        - scheduler
        # suggested to let this restart after X runs for reliability
        # https://medium.com/handy-tech/airflow-tips-tricks-and-pitfalls-9ba53fba14eb
        - --num_runs=10
        envFrom:
        - configMapRef:
            name: airflow-env
        imagePullPolicy: Always
        ports:
        - containerPort: 8080
          protocol: TCP
        resources:
          limits:
            memory: 2Gi
          requests:
            memory: 2Gi
      - image: gcr.io/cloudsql-docker/gce-proxy:1.11
        name: cloudsql-proxy
        command: ["/cloud_sql_proxy"]
        args: ["-instances=$(DB_CONNECTION_NAME)=tcp:5432"]
        envFrom:
        - configMapRef:
            name: airflow-env
      restartPolicy: Always
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  labels:
    app: airflow-worker
    tier: worker
    stack: airflow
  name: airflow-worker
spec:
  replicas: 16
  selector:
    matchLabels:
      app: airflow-worker
  # strategy:
  #   rollingUpdate:
  #     maxSurge: 2
  #     maxUnavailable: 2
  #   type: RollingUpdate
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: airflow-worker
        tier: worker
        stack: airflow
    spec:
      containers:
      - name: airflow-worker
        image: gcr.io/sixty-secure/conductor:commodity-in-conductor
        command:
        - /usr/local/bin/airflow-entry.sh
        - worker
        - --concurrency=1
        envFrom:
        - configMapRef:
            name: airflow-env
        imagePullPolicy: Always
        ports:
        - containerPort: 8080
          protocol: TCP
        resources:
          limits:
            memory: 8Gi
            cpu: 1000m
          requests:
            memory: 2Gi
            cpu: 300m
      - image: gcr.io/cloudsql-docker/gce-proxy:1.11
        name: cloudsql-proxy
        command: ["/cloud_sql_proxy"]
        args: ["-instances=$(DB_CONNECTION_NAME)=tcp:5432"]
        envFrom:
        - configMapRef:
            name: airflow-env
      restartPolicy: Always
      nodeSelector:
        cloud.google.com/gke-nodepool: large-preemptible
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: celery-redis
  # these labels can be applied automatically
  # from the labels in the pod template if not set
  # labels:
  #   app: redis
  #   role: master
  #   tier: backend
spec:
  # this replicas value is default
  # modify it according to your case
  replicas: 1
  # selector can be applied automatically
  # from the labels in the pod template if not set
  # selector:
  #   matchLabels:
  #     app: guestbook
  #     role: master
  #     tier: backend
  template:
    metadata:
      labels:
        app: celery-redis
        role: master
        tier: backend
        db: redis
    spec:
      containers:
      - name: celery-redis
        image: launcher.gcr.io/google/redis4
        args: [
          "--maxmemory", "2gb",
          "--maxmemory-policy", "allkeys-lru",
          "--timeout", "10800",  # 3 hours
          "--tcp-backlog", "10000"]
        ports:
        - containerPort: 6379
        resources:
          requests:
            memory: 2Gi
      volumes:
      - name: celery-redis-data
        persistentVolumeClaim:
          claimName: celery-redis-data
      nodeSelector:
        cloud.google.com/gke-nodepool: small
---
# Request a persistent volume from the cluster using a Persistent Volume Claim.
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: celery-redis-data
  annotations:
    volume.alpha.kubernetes.io/storage-class: default
spec:
  accessModes: [ReadWriteOnce]
  resources:
    requests:
      storage: 10Gi
---
apiVersion: v1
kind: Service
metadata:
  name: celery-redis
  labels:
    app: celery-redis
    role: master
    tier: backend
    db: redis
spec:
  ports:
    # the port that this service should serve on
  - port: 6379
    targetPort: 6379
  selector:
    app: celery-redis
    role: master
    tier: backend
